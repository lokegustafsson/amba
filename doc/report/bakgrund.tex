\chapter{Bakgrund}

% Att läsa källkod är ett sätt att förstå program, men ibland är det gynnsamt att istället betrakta
% maskinkoden direkt.

% \subsection{Tidigare arbete}

% förklara "protokollstack", "symbolisk exekvering", "dynamisk analys"
Flertalet arbeten existerar inom domänen binäranalys och dess analystekniker. Fowze \cite{fowze_mem_vul}
beskriver verkyget \emph{SEESAW}, ett verktyg för att analysera
minnessårbarheter i protokollstacken. Fokuset ligger på att undersöka USB och
blåtandsmoduler med hjälp av en hybrid av analysmetoder: statisk analys och
dynamisk analys. \emph{SEESAW} implementerar en algoritm som tillämpar
bidirektionell kommunikation mellan en statisk analys som tillhandahåller ett
mål i binären till en riktad symbolisk exekvering dvs den dynamiska analysen som
ger tillbaka en bestämd funktionspekare för att komplettera och öka precisionen
av analysen.  

\section{Mål}
Detta projekt ämnar utveckla ett binäranalysverktyg för generell reverse
engineering, det vill säga en applikation vars uppgift är att analysera binära
program utan kännedom om källkoden utifrån ett datorsäkerhetsperspektiv.
Verktyget ska ha en korrekt och testbar förståelse av det analyserade programmet
och ska samtidigt kunna kommunicera denna till användaren genom visualisering.
Visualiseringen ska presenteras i ett grafiskt användargränssnitt där användaren
kan interaktivt stega igenom det binära programmet och själv välja vilka beslut
som görs gällande exempelvis programhopp. Funktionaliteten i verktyget uppnås
med hjälp av symbolisk exekvering, och därigenom kombineras fördelarna i
automatiska och manuella analysmetoder.

% Utveckla syfte (förstå nyttan och det akademiskt relevanta i arbetet)
Verktyget ämnar att genom mänskligt läsbara representationer av programmets 
beteende, öka användarens abstrakta förståelse av det. Verktyget ska vara 
användbart för att öka användarens abstrakta förståelse av ett program då källkod 
saknas. Det vill säga verktyget ska hjälpa användaren att resonera om programmet 
generellt. 

\section{Användningsområden}

Att kunna avgöra ett programs beteende utifrån endast exkeverbar (binär) 
kod är viktigt när man undersöker potentiellt skadlig mjukvara eftersom
dess källkod oftast är okänd. För att upptäcka pågående, och motverka 
framtida attacker är det viktigt att förstå hur attackerna är utformade och
hur de beteer sig. 

Binär analys är också användbart då tredje-parts bibliotek används.
Att analysera säkerheten hos ett program kan behöva ske utan att involvera 
dess utgivare. Då är det användbart att kunna dra slutsatser om programmet 
endast ifrån dess maskinkod. 

Förutom att analysera program där källkoden inte är tillgänglig så är det även 
användbart att analysera ett programs maskinkod för att undersöka kompilatorbuggar.

%\section{akademisk relevans}

\section{Avgränsningar}

Att skapa en en exekveringsmotor med stöd för bland annat symbolisk exekvering
skulle i praktiken innebära implementering av en emulator. Det är en relativ
stor och tidskrävande uppgift som dessutom kräver nogrann testning för att vara
korrekt och tillförlitlig. För att fastställa korrekthet ska applikationen
därför utnyttja existerande verktyg för att exekvera programmet med stöd för
symbolisk exekvering. Detta möjliggör också bredare plattformssupport jämfört
med en hemmasnickrad emulator.


\subsection{\stoe}

\stoe\cite{s2e} är en plattform för symbolisk exekvering som bygger på QEMU:s
virtuella maskin och använder KLEE\cite{klee}, en motor för symbolisk
exekvering, som interpreter för att möjliggöra symbolisk exekvering. \stoe\ är i
sin tur utbyggbart med möjlighet för användaren att skriva ett eget plugin för
att utföra analyser och används inom säkerhetsforskning för att till exempel
analysera skadlig kod. \stoe\ användes som del av Galactica-systemet som spelade
i DARPA Cyber Grand Challenge\cite{s2e_website}. \stoe\ är öppen källkod,
väldokumenterat och underhålls aktivt.

\subsection{SymQEMU}

Ett alternativt verktyg för symbolisk exekvering är symQEMU\cite{symqemu},
som också kombinerar QEMU:s virtuella maskin med KLEE:s motor för symbolisk
exekvering. Till skillnad från \stoe\ kompilerar SymQEMU KLEE in i den
analyserade binären och har jämförelsevis hög prestanda. Däremot har SymQEMU
bristfällig dokumentation och är ej aktivt uppdaterat.

\subsection{Beslut}

Då SymQEMU ej uppdateras aktivt och har bristfällig dokumentation kommer \stoe\
användas. Projektet avgränsas i och med att existerande verktyg (\stoe) kommer
användas istället för att bygga en motor för symbolisk exekvering från grunden.

\subsection{Begränsningar}

Att använda \stoe innebär att arbetet avgränsas till att, i praktiken, skapa
ett plugin som avlyssnar och styr motorn. Varken emulator eller motor ska
byggas och de uppgifter som ingår i att skapa en exekveringsmotor exkluderas.

Det innebär att fokus flyttas ifrån motorns tekniska detaljer till resterande
jobbet med att utveckla en användbar slutprodukt som bygger ut \stoe:s redan
existerande funktionalitet med ett grafiskt användargränsnitt och möjlighet att
stega igenom, analysera och interaktivt besluta om värden under exekvering.

Beslutet innebär också att applikationens utformning blir bunden till \stoe:s
tekniska begränsningar.

Begreppet \textit{reverse engingeering} syftar på processen att söka insikt i hur en produkt 
(enhet/process/mjukvara/verktyg/system) arbetar, utan en etablerad insikt i dess interna 
uppbyggnad. Med andra ord syftar reverse engineering på att dekonstruera en produkt för att 
öka förståelsen av den. Detta görs genom att med olika metoder plocka isär produkten för 
att förstå hur den utför ett arbete. Reverse engineering är ett fundamentalt verktyg då insikt 
om en produkts design behövs men designspecifikationer ej existerar eller är tillgängliga. 
Reverse engineering har flera användningsområden, däribland då äldre produkter, vars design 
inte längre är tillgänglig, behöver undersökas, eller när funktionalitet försvunnit i 
utvecklingsaproccesen och behöver återfinnas. Reverse engineering är också användbart för 
att analysera fel som uppstår, för att förbättra delkomponenter eller för att diagnostisera 
en produkt.

För att bilda en allmän förståelse om ett program krävs både \textit{korrekt} och
\textit{abstrakt} förståelse. I detta avseende syftar \textit{korrekt} på
avsaknaden av felaktiga slutsatser och \textit{abstrakt} på möjligheten att
resonera om programmet generellt i motsats till att resonera om en specifik
konkret indata i taget.

% Metod 1-2, att läsa kod, kan ge en \textit{abstrakt} förståelse av vad
% programmet gör, men för att verifiera att huruvida resonemanget är korrekt krävs
% hypotestestning vilket kräver att programmet körs. Således går det inte att
% bilda en \textit{korrekt} förståelse genom att enbart läsa kod.

% Metod 3-5, att köra programmet på testfall, ger framförallt en
% black-box-förståelse av programmet. Tillgången till binären och
% exekveringsmiljön används endast som ett verktyg för att generera nya testfall.
% Fuzzing och concolic testing kan köras helautomatiskt och är \textit{korrekta}.
% Men ofta är en tillräckligt täckande sökning av indatarummet omöjlig, och då kan
% den automatiska analysen ha missat ett kvalitativt annorlunda beteende. Dessutom
% ger en omfattande uppsättning indata-utdata-par inte användaren samma
% information som källkoden ger. Därmed är helautomatiska analysmetoder inte
% \textit{abstrakta}. Notera att det inte nödvändigtvis tyder på en brist i den
% automatiska analysen att ett kvalitativt annorlunda beteende missas, för det
% gömda beteendet skulle kunna vara en konsekvens av komplicerad kod, som till
% exempel ett hoppvilkor beroende på en kryptografisk hash av indatan. Men en
% analysmetod borde kunna peka ut var dess förståelse tar slut, snarare än att
% utelämna detta fullständigt vilket är vad avsaknaden av testfall visar sig som.

% Med metod 6, en debugger, kan användaren följa exekveringen för en viss indata
% utan att riskera att missförstå hur datan transformeras. Om användaren har ett
% oändligt tålamod kan de göra detta om och om igen för olika indata genererade
% med till exempel fuzzing. Varje genomstegning ger information om koden som
% behandlar indatan men också viss information om övrig kod -- till exempel kan
% ett svårtaget hopp indikera en plats för användaren att rikta sin uppmärksamhet
% mot. Detta ger en både \textit{korrekt} och \textit{abstrakt} förståelse, men
% med en orimlig manuell arbetsbörda för användaren.

En helautomatisk \textit{korrekt} metod kan ge en \textit{abstrakt} förståelse
om processens förlopp visualiseras för användaren. Valet mellan manuell
arbetsbörda som ger djup förståelse och en testfallsgenerationsdriven process
som ger översiktlig förståelse kan genomföras av användaren om verktygen stödjer
hela spektrummet.

För att klargöra distinktionen mellan manuell och automatiska metoder för
binäranalys används följande use cases:

\begin{lstlisting}[
    label={list:first},
    language=Python,
    caption=Use case manuella metoder,
    frame=single
    ]
# Givet sträng-input från stdin
s = input()
if sha256(s) == "välkänd hash":
  print("Winner winner chicken dinner")
else:
  print("you lose")

\end{lstlisting}

I use cases där det existerar kända konstanter, något som är typiskt i fall som
involverar kryptografi i olika utsträckning, är det rimligt att tillämpa
manuella metoder för att bilda förståelse om programmet. Genom att inspektera
ett binärt program innehållande ovan källkod kan det enkelt hittas en konstant
associerad till sha-256 algoritmen och därmed bilda förståelse om programmet.

I ovan fall är det dessutom orimligt att tillämpa automatiska metoder eftersom
dessa, såsom concolic testing, genererar alltför stora symboliska
representationer och hade i det ovan exemplet krävt att det går att hitta
inversen till en given SHA-256 hash vilket idag är omöjligt och leder därmed
till att alla paths inte undersöks.

\begin{figure}
  \begin{lstlisting}[
      label={list:first},
      language=Python,
      frame=single
      ]
  # Givet sträng-input från stdin
  s = input()
  if s == "secret":
    print("Winner winner chicken dinner")
  else:
    print("you lost")
  \end{lstlisting}
  \caption{Use case manuella metoder}
\end{figure}

Ett motsatt fall är ovan och lämpas väl att undersökas med automatiska
metoder eftersom det är tidskrävande att manuellt välja slumpvalda värden på s
för att hitta den korrekta branchen. Istället lämpar concolic testing, dvs en
automatisk metod, sig väl i detta fallet eftersom concolic testing väljer olika
konkreta värden samtidigt som den tillämpar symbolisk exekvering med symboliska
värden som följer den givna branchen, t.ex. om \lstinline{s == "hej"} vilket
motsvarar att programmet väljer else-branchen och printar \lstinline{"you lost"}. 
Detta upprepas med nya exekveringsvägar och till slut hittas vilken input som ger
\lstinline{print("you won")}-branchen. 

\subsubsection{Symbolisk Exekvering}

Att exekvera ett program symboliskt innebär att representera värden utefter 
programflödet som symboliska restriktioner, vilka kan lösas av automatiserade 
teoremlösare (\emph{SMT solver}). En symbolisk körning representerar flera konkreta 
körningar eftersom de (symboliska) värden som används representerar grupper av 
konkreta värden vilka har gemensamt hur de påverkar programmets flöde. 

Vägar i programmets kontrollflöde utforskas med symboliska uttryck för de 
begränsningar som finns på programmets variablar - vilka egenskaper de måste uppnå 
för att just denna väg ska kunna följas. Eftersom de symboliska värdena har kapacitet 
att representera grupperingar av konkreta värden istället för enskilda sådana, 
utförs en generaliserad testning av programmet, som ger insikt i hur programmet 
beteer sig givet en grupp av parametrar som alla på grund av någon eller några 
gemensamma egenskaper, orsakar gemensamma beteenden i programmet. 

En symbolisk exekveringsmotor arbetar genom att först representera programmets input 
som symboliska variablar, vilka vid starten inte har några begränsningar, och när 
programflödet når en förgrening som baseras på någon av de symboliska variablerna, 
så väljer motorn en gren och tillsätter den grenens restriktioner på den symboliska 
variabeln för alla vägar som fortsätter utefter förgreningen. Operationer på värden 
under körningens väg översätts till symboliska operationer på motsvarande symboliska 
variabler. \cite{klee} När körning utefter grenen är slutförd så kan motorn börja om 
vid förgreningen och utforska andra alternativ med samma metodik. De tillståndsvillkor 
som en viss väg visas ha byggs därför successivt upp genom att motorn utökar de 
symboliska variablerna till villkorliga uttryck allt eftersom vägen följs. 

De fel som hittas genom symbolisk exekvering är tillförlitliga då metoden ej ger falskt 
positiva resultat. Huruvida villkorsblock av program är nårbara kan evalueras med 
säkerhet eftersom de krav som måste uppfyllas för att följa vägen dit dokumenteras under 
den symboliska körningen, och resulterar i fullständiga symboliska representationer 
som en automatiserad teoremlösare (SMT solver) kan appliceras på. 

Symbolisk exekvering är användbart för att resonera kring hur programmet beter sig 
beroende på grupperingar av input. För program där få värden tar gemensamma vägar blir 
fördelen över att istället använda dynamisk testning av konkret data dock låg. 

Eftersom symbolisk exekvering kan leda till \emph{path explosion} är det inte effektivt 
att alltid undersöka alla förgreningar i ett program. Exempel på metoder för att undvika 
path explosion är \emph{state-merging} och \emph{heuristics}. 

\subsubsection{Statisk och dynamisk binäranalys}
En annan typ av kategorisering av olika analysmetoder som fokuserar på hur
analysen genomförs delar metoderna i två grupper: statisk och dynamisk analys
\cite{dynamic_bin_analysis}.

Statisk analys syftar på analys som går att göra utan att exekvera programmet
som analyseras. Exempel på statisk binäranalys är metod 1-2, alltså att
disassembla binären och/eller visualisera kod \cite{dynamic_bin_analysis}.

Dynamisk analys går ut på att analysera ett program under exekvering
\cite{dynamic_bin_analysis}. Exempel på dynamisk binäranalys är metod 3-6. I
alla fall krävs någon typ av injektion av kod eller data i programmet i syfte
att kunna extrahera viktig information under programmets körning
\cite{dynamic_bin_analysis}. Många avancerade dynamiska metoder som t.ex.
concolic testing kräver symbolisk exekvering som går ut på att tilldela
symboliska värden till variabler och se hur dessa påverkar programhopp och
förgreningar och vad för möjliga värden som denna symbol kan inneha under
exekvering. I fallet med concolic testing används denna information för att,
med hjälp av en SMT-solver ta fram konkreta värden som leder till att
programmet kör till en program-distination som består av ett krasch.

\subsubsection{Existerande verktyg}
Det kan finnas flera metoder för analys av binärprogram och det finns ganska
många verktyg idag som stödjer ett eller flera av dessa metoder. Det finns
många tillgängliga binäranalysverktyg men några populära binäranalysverktyg är
Ghidra\cite{ghidra_website} och Angr\cite{angr_web}.

% Sure I am referencing to the Ghidra website, but this is done by others as
% well because Ghidra has no report afaik. An example report that uses ghidra
% https://rp.os3.nl/2019-2020/p49/report.pdf

% Vidare har angr t.ex. sagt att "om man använder angr som en komponent i sin
% projekt ska man helst citera en viss rapport", men vi beskriver bara med
% några ord vad angr är och använder den till inget.

Ghidra är ett \emph{reverse engingeering} ramverk utvecklat av USA:s NSA
(National Security Agency) och kan disassembla en binär till pseudo-C-kod.
Ghidra har också en debugger och funktionsgraf. Debuggern ska underlätta binär
debugging genom att integrera med andra funktioner i Ghidra. Funktionsgrafen
låter användaren se hur programmet är uppbyggt visuellt och hur olika
funktioner interagerar med varandra. Funktionaliteter kan utökas eller andra
funktioner utvecklas genom plugins till Ghidra\cite{ghidra_use_cases}. Ghidra
tillåter även automatisering genom att skriva skript. Ett exempel är ett skript
som hittar exempelvis sårbarhet i form av funktionsanropp till potentiellt
osäkra API-anrop genom statisk analys\cite{ghidra_script}.

Angr är en binäranalysverktyg med stöd för både statiska och dynamiska analyser
med hjälp av symbolisk exekvering. Angr har, som Ghidra, stöd för
disassemblering till pseudo-C-kod och många analyser man kan utföra. Angr är
baserat på en emulator skriven i Python med stöd för symbolisk exekvering och
analyser utförs genom Python-skript som interagerar med Angrs API. Angr har
använts för att framställa skript som kan utföra \emph{reverse engineering},
sårbarhetssökning och fungera som exploateringsverktyg\cite{angr_docs}.
