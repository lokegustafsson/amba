Under \emph{BlueHat} 2019 gav \emph{MSRC} (\emph{Microsoft Security Response Center}) en överblick
över Microsofts taktiker för hur de hanterar säkerhetsbrister i deras produkter och tjänster.
\cite{miller19} Taktikerna som listades var att
\begin{itemize}
	\item eliminera säkerhetsbristerna från början;
	\item implementera metoder för att försvåra utnyttjande av säkerhetsbrister;
	\item minimera platserna där attackerarna kan göra skada och förhindra åtkomst; samt slutligen
	\item minimera tidsfönstret då attackerare har tillgång till systemet med hjälp av aktiv övervakning.
\end{itemize}
Enligt Miller \cite{miller19} härstammar ungefär 70 procent av alla Microsofts CVEr från minnessäkerhetsbuggar. Om
hela klasser av säkerhetsbrister kan eliminieras genom att utveckla nya verktyg som underlättar för
utvecklare att finna dem kan det leda till stor påverkan på antalet sårbarheter.

% probably need a source for this paragraph
Det är särskilt fördelaktigt att undersöka minnessäkerhetsbuggar genom att
betrakta maskinkod. Genom att betrakta maskinkod bildar man en lågnivåförståelse
av en binär eftersom den fullständiga målkoden som kompilatorn genererat
existerar på denna nivån. Med en lågnivåförståelse kan man också härleda hur
binären interagerar med minnet genom att bland annat analysera minneslayouten
och den underliggande datastrukturen för att hitta problem vid minnesallokering
och minnesdeallokering, och därigenom hitta minnessäkerhetsbuggar.

Det finns ett flertal metoder för att analysera en exekverbar binär. Exempel på dessa är att: 
\begin{enumerate}
  \item disassemblera binären och läsa dess funktioner för att förstå vad de gör.
  \item dekompilera assemblykoden med ett verktyg som ger pseudokod, och sedan läsa denna mer
    läsbara koden.
  \item köra binären på speciella testfall och jämföra svaret med vad som förväntas. Om
    programmet implementerar en specifikation kan en existerande testsamling användas.
  \item fuzztesta binären, det vill säga automatiskt generera testfall tills ett orsakar en crash eller
    annat oönskat beteende i binären. Många fuzztestmotorer skapar testfall med en evolutionär
    algoritm, och många använder instrumentering över vilka programhopp som tas för att bedöma
    testfalls nyttighet.
  \item använda concolic testing, alltså fuzzing där en SMT solver genererar nya testfall genom att
    lösa för testfall som orsakar annorlunda programhopp.
  \item stega igenom programmet i en debugger för att se exakt vad programmet gör med viss input.
\end{enumerate}

Problematisk minneshantering har potential att påverka ett programs korrekthet och 
kan utnyttjas av fientliga aktörer i skadliga syften. Att minne hanteras på ett 
osäkert sätt är inte ovanligt, speciellt då proggrammet är skrivet i ett språk som är 
"memory unsafe" som exempelvis C/C++. Det är då lätt att vid utveckling av program 
göra misstag som introducerar sårbarheter, och kan vara svårare att upptäcka dessa 
sårbarheter när de väl introducerats, speciellt om det inkorrekta beteendet endast 
uppstår under körning med specifika indata.

Att läsa källkod är ett sätt att förstå program, men ibland är det gynnsamt att istället betrakta
maskinkoden direkt. Detta kan vara för att

Begreppet \textit{reverse engingeering} syftar på processen att söka insikt i hur en produkt 
(enhet/process/mjukvara/verktyg/system) arbetar, utan en etablerad insikt i dess interna 
uppbyggnad. Med andra ord syftar reverse engineering på att dekonstruera en produkt för att 
öka förståelsen av den. Detta görs genom att med olika metoder plocka isär produkten för 
att förstå hur den utför ett arbete. Reverse engineering är ett fundamentalt verktyg då insikt 
om en produkts design behövs men designspecifikationer ej existerar eller är tillgängliga. 
Reverse engineering har flera användningsområden, däribland då äldre produkter, vars design 
inte längre är tillgänglig, behöver undersökas, eller när funktionalitet försvunnit i 
utvecklingsaproccesen och behöver återfinnas. Reverse engineering är också användbart för 
att analysera fel som uppstår, för att förbättra delkomponenter eller för att diagnostisera 
en produkt.

För att bilda en allmän förståelse om ett program krävs både \textit{korrekt} och
\textit{abstrakt} förståelse. I detta avseende syftar \textit{korrekt} på
avsaknaden av felaktiga slutsatser och \textit{abstrakt} på möjligheten att
resonera om programmet generellt i motsats till att resonera om en specifik
konkret indata i taget.

% Metod 1-2, att läsa kod, kan ge en \textit{abstrakt} förståelse av vad
% programmet gör, men för att verifiera att huruvida resonemanget är korrekt krävs
% hypotestestning vilket kräver att programmet körs. Således går det inte att
% bilda en \textit{korrekt} förståelse genom att enbart läsa kod.

% Metod 3-5, att köra programmet på testfall, ger framförallt en
% black-box-förståelse av programmet. Tillgången till binären och
% exekveringsmiljön används endast som ett verktyg för att generera nya testfall.
% Fuzzing och concolic testing kan köras helautomatiskt och är \textit{korrekta}.
% Men ofta är en tillräckligt täckande sökning av indatarummet omöjlig, och då kan
% den automatiska analysen ha missat ett kvalitativt annorlunda beteende. Dessutom
% ger en omfattande uppsättning indata-utdata-par inte användaren samma
% information som källkoden ger. Därmed är helautomatiska analysmetoder inte
% \textit{abstrakta}. Notera att det inte nödvändigtvis tyder på en brist i den
% automatiska analysen att ett kvalitativt annorlunda beteende missas, för det
% gömda beteendet skulle kunna vara en konsekvens av komplicerad kod, som till
% exempel ett hoppvilkor beroende på en kryptografisk hash av indatan. Men en
% analysmetod borde kunna peka ut var dess förståelse tar slut, snarare än att
% utelämna detta fullständigt vilket är vad avsaknaden av testfall visar sig som.

% Med metod 6, en debugger, kan användaren följa exekveringen för en viss indata
% utan att riskera att missförstå hur datan transformeras. Om användaren har ett
% oändligt tålamod kan de göra detta om och om igen för olika indata genererade
% med till exempel fuzzing. Varje genomstegning ger information om koden som
% behandlar indatan men också viss information om övrig kod -- till exempel kan
% ett svårtaget hopp indikera en plats för användaren att rikta sin uppmärksamhet
% mot. Detta ger en både \textit{korrekt} och \textit{abstrakt} förståelse, men
% med en orimlig manuell arbetsbörda för användaren.

En helautomatisk \textit{korrekt} metod kan ge en \textit{abstrakt} förståelse
om processens förlopp visualiseras för användaren. Valet mellan manuell
arbetsbörda som ger djup förståelse och en testfallsgenerationsdriven process
som ger översiktlig förståelse kan genomföras av användaren om verktygen stödjer
hela spektrummet.

För att klargöra distinktionen mellan manuell och automatiska metoder för
binäranalys används följande use cases:

\begin{lstlisting}[
    label={list:first},
    language=Python,
    caption=Use case manuella metoder,
    frame=single
    ]
# Givet sträng-input från stdin
s = input()
if sha256(s) = "välkänd hash":
  print("Winner winner chicken dinner")
else:
  print("you lose")

\end{lstlisting}

I use cases där det existerar kända konstanter, något som är typiskt i fall som
involverar kryptografi i olika utsträckning, är det rimligt att tillämpa
manuella metoder för att bilda förståelse om programmet. Genom att inspektera
ett binärt program innehållande ovan källkod kan det enkelt hittas en konstant
associerad till sha-256 algoritmen och därmed bilda förståelse om programmet.

I ovan fall är det dessutom orimligt att tillämpa automatiska metoder eftersom
dessa, såsom concolic testing, genererar alltför stora symboliska
representationer och hade i det ovan exemplet krävt att det går att hitta
inversen till en given SHA-256 hash vilket idag är omöjligt och leder därmed
till att alla paths inte undersöks.

\begin{lstlisting}[
    label={list:first},
    language=Python,
    caption=Use case manuella metoder,
    frame=single
    ]
# Givet sträng-input från stdin
s = input()
if s == "secret":
  print("Winner winner chicken dinner")
else:
  print("you lost")
\end{lstlisting}

Ett motsatt fall är ovan och lämpas väl att undersökas med automatiska
metoder eftersom det är tidskrävande att manuellt välja slumpvalda värden på s
för att hitta den korrekta branchen. Istället lämpar concolic testing, dvs en
automatisk metod, sig väl i detta fallet eftersom concolic testing väljer olika
konkreta värden samtidigt som den tillämpar symbolisk exekvering med symboliska
värden som följer den givna branchen, t.ex. om \lstinline{s == "hej"} vilket
motsvarar att programmet väljer else-branchen och printar \lstinline{"you lost"}. 
Detta upprepas med nya exekveringsvägar och till slut hittas vilken input som ger
\lstinline{print("you won")}-branchen. 


