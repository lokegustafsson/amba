I detta avsnitt förklaras bakgrund och problembeskrivning till projektet. Innan
problemen kan beskrivas måste vi förstå några centrala idéer och teorier inom
domänen. Först beskrivs olika metoder inom binäranalys, sedan ges en bakgrund
till symbolisk exekvering, den underliggande tekniken inom symbolisk fuzzing, och vilka
problem tekniken löser. Detta följs upp med en mer detaljerad beskrivning av symbolisk
exekvering och fuzzing. Avslutningsvis, beskrivs problem som en symbolisk exekveringsmotor
står inför och några möjliga lösningar till dessa problem.
% , samt motiveringar till detta
% projekt.

\section{Binäranalys}
\label{sec:binar_analys}
Inom skadeprogramsanalys (jfr eng. malware analysis) och reverse engeneering
är binäranalys nödvändig eftersom programmet som ska analyseras oftast endast
tillgänglig som maskinkod~\cite{andriesse2018}.

Förutom då endast maskinkoden är tillgänglig så är binäranalys också användbart för att
upptäcka och undersöka minnessårbarheter. Det beror på det semantiska gapet mellan ett
högnivå programspråk och maskinkod. Det är inte trivialt att argumentera för programmets
beteende innan och efter kompilering
till maskinkod och hur väl dessa mostsvarar varandra. Genom att betrakta
maskinkoden kan man ``undersöka vad programmet faktiskt gör istället för vad
man tror att det gör''~\cite{andriesse2018}. Avslutningsvis, kan sårbarheter
introduceras i kompileringssteget på grund av fel i kompilatorer som oftast är
sällsynta men inte obefintliga~\cite{silentbugsmatter}.

Ett flertal metoder används för att analysera maskinkod:
\begin{enumerate}
    \item disassemblera binären och läsa dess funktioner för att förstå vad de gör~\cite{ghidra_website}.
    \item dekompilera maskinkoden med ett verktyg som ger pseudokod, och sedan manuellt undersöka denna mer läsbara koden~\cite{ghidra_website}.
    \item använda fuzzing på programmet, det vill säga automatiskt generera testfall tills ett orsakar en crash eller
          annat oönskat beteende~\cite{8371326}.
    \item använda symbolisk fuzzing på programmet, där nya testfall genereras med hjälp av tidigare för att effektivt täcka fler vägar.~\cite{sage}.
\end{enumerate}

% Problematisk minneshantering har potential att påverka ett programs korrekthet och
% kan utnyttjas av fientliga aktörer i skadliga syften. Att minne hanteras på ett
% osäkert sätt är inte ovanligt, speciellt då proggrammet är skrivet i ett språk som är
% ''memory unsafe'' som exempelvis C/C++. Det är då lätt att vid utveckling av program
% göra misstag som introducerar sårbarheter, och kan vara svårare att upptäcka dessa
% sårbarheter när de väl introducerats, speciellt om det inkorrekta beteendet endast
% uppstår under körning med specifika indata.

% Begreppet \textit{reverse engingeering} syftar på processen att söka insikt i hur en produkt
% (enhet/process/mjukvara/verktyg/system) arbetar, utan en etablerad insikt i dess interna
% uppbyggnad. Med andra ord syftar reverse engineering på att dekonstruera en produkt för att
% öka förståelsen av den. Detta görs genom att med olika metoder plocka isär produkten för
% att förstå hur den utför ett arbete. Reverse engineering är ett fundamentalt verktyg då insikt
% om en produkts design behövs men designspecifikationer ej existerar eller är tillgängliga.
% Reverse engineering har flera användningsområden, däribland då äldre produkter, vars design
% inte längre är tillgänglig, behöver undersökas, eller när funktionalitet försvunnit i
% utvecklingsaproccesen och behöver återfinnas. Reverse engineering är också användbart för
% att analysera fel som uppstår, för att förbättra delkomponenter eller för att diagnostisera
% en produkt.

%De olika metoderna har sina för- och nackdelar och är olika effektiva. Dessutom
%är de applicerbara i olika situationer. /detta skrev Joachim varmluft om...

För att bilda förståelse för ett program krävs att insikter är både korrekta % “För att bilda en allmän … “ förenkla/förtydliga mvh Joachim
och abstrakta. I detta avseende syftar korrekt på avsaknaden av felaktiga slutsatser
och abstrakt på möjligheten att resonera om programmet generellt i
motsats till att resonera om en specifik konkret indata i taget.

Metod 1-2, att läsa kod, kan ge en abstrakt förståelse av vad
programmet gör, men för att verifiera huruvida resonemanget är korrekt krävs
hypotestestning vilket kräver att programmet körs. Således går det inte att
skaffa sig en korrekt förståelse genom att enbart läsa kod.

Metod 3-4, att köra programmet på testfall, ger framförallt en
black-box-förståelse av programmet. Tillgången till binären och
exekveringsmiljön används endast som ett verktyg för att generera nya testfall.
Fuzzing och symbolisk fuzzing kan köras helautomatiskt och är korrekta.
Vid fuzzing är en täckande sökning av indatarummet oftast omöjlig, och då kan
den automatiska analysen ha missat ett kvalitativt annorlunda beteende. Dessutom
ger en omfattande uppsättning indata-utdata-par inte användaren samma
information som källkoden ger. Därmed är helautomatiska analysmetoder inte
abstrakta. Det kan finnas gömda beteenden som är omöjliga att hitta med en automatisk
analys, som till exempel ett hoppvilkor som beror på en kryptografisk hash av indatan.
Detta är en fundamental begränsning som inte kan lösas med bättre verktyg.
En analysmetod borde kunna peka ut var dess förståelse tar slut, snarare än att
utelämna detta fullständigt vilket är vad avsaknaden av testfall visar sig som.

% En helautomatisk \textit{korrekt} metod kan ge en \textit{abstrakt} förståelse
% om analysprocessens förlopp visualiseras för användaren. Valet mellan manuell
% arbetsbörda som ger djup förståelse och en testfallsgenerationsdriven process
% som ger översiktlig förståelse kan genomföras av användaren om verktygen stödjer
% hela spektrumet.

\subsection{Automatiska och manuella metoder för binäranalys}
För att klargöra distinktionen mellan manuella och automatiska metoder för
binäranalys kan vi betrakta följande exempel:

\begin{figure}
    \begin{lstlisting}[
    label={list:first},
    language=Python,
    frame=single
    ]
# Givet sträng-input från stdin
s = input()
if sha256(s) == saved_hash:
  allow_access()
else:
  deny_access()
\end{lstlisting}
    \caption{Exempelprogram där det är fördelaktigt att att använda manuella metoder för binäranalys}
    \label{fig:manual_method_example}
\end{figure}

I fall där det existerar kända konstanter, något som är typiskt i fall som
involverar kryptografi i olika utsträckning, är det rimligt att tillämpa
manuella metoder för att bilda förståelse för programmet. Genom att inspektera
maskinkoden för program motsvarande figur~\ref{fig:manual_method_example} kan
det enkelt hittas en konstant relaterad till sha256-algoritmen for att beräkna
hash funktionen och därmed bilda förståelse för programmet. I detta fall är det
dessutom orimligt att tillämpa automatiska metoder eftersom dessa, såsom
konkolisk testning, genererar alltför stora symboliska representationer och hade
i det ovan exemplet krävt att det går att hitta inversen till en given
sha256-hash vilket idag är omöjligt och leder därmed till att alla vägar i
programflödet inte undersöks.

\begin{figure}
    \begin{lstlisting}[
    label={list:first},
    language=Python,
    frame=single
    ]
# Givet sträng-input från stdin
s = input()
if s == "secret":
  allow_access()
else:
  deny_access()
\end{lstlisting}
    \caption{Exempelprogram där det är fördelaktigt att att använda automatiska metoder för binäranalys}
    \label{fig:automatic_method_example}
\end{figure}

Ett motsatt fall är exemplet i figur~\ref{fig:automatic_method_example} som passar
att undersökas med automatiska metoder eftersom det är tidskrävande
att manuellt välja slumpvalda värden på \texttt{s} för att hitta den korrekta
vägen. Istället lämpar symbolisk fuzzing sig väl i detta fallet. Eftersom
symbolisk fuzzing väljer olika konkreta värden samtidigt som den tillämpar
symbolisk exekvering med symboliska värden som följer den givna vägen, t.ex.\
om \lstinline{s == "annat"} vilket motsvarar att programmet väljer else-vägen
\lstinline{deny_access()}. Detta upprepas med nya exekveringsvägar och till slut
hittar den indata som ger \lstinline{allow_access()}-vägen.


\subsection{Statisk och dynamisk binäranalys}
En annan typ av kategorisering av olika analysmetoder som fokuserar på hur
analysen genomförs delar metoderna i två grupper: statisk och dynamisk
analys~\cite{dynamic_bin_analysis}.

Statisk analys syftar på analys som går att göra utan att exekvera programmet
som analyseras. Exempel på statisk binäranalys är metod 1--2 beskrivet tidigare
i avsnitt~\ref{sec:binar_analys}, alltså att disassembla binären och/eller
visualisera kod~\cite{dynamic_bin_analysis}.

Dynamisk analys går ut på att analysera ett program under
exekvering. Exempel på dynamisk binäranalys är metod 3--6 i
avsnitt~\ref{sec:binar_analys}. I alla fall krävs någon typ av injektion av kod
eller data i programmet i syfte att kunna extrahera viktig information under
programmets exekvering~\cite{dynamic_bin_analysis}.


\subsection{Minnessårbarheter}
I praktiken uppgör minnessäkerhetsbrister ungefär 70 procent av alla
sårbarheter~\cite{miller19}. Minnessårbarheter kan påverka programflödet (jfr
eng. \emph{control flow}) i ett program och alltså dess beteende. Det kan
vara alvarligt om en angripare kan läsa delar av minnet som inte ska vara
läsbara men det mest allvarliga är skrivaccess utanför minnesgränser. En
angripare kan använda det för att t.ex. exekvera godtyckliga kommandon på
datorn som kör programmet~\cite{computer_security_cs161}, alltså \emph{remote
    code execution}.

I en perfekt värld hade det varit fördelaktigt att undvika alla sårbarheter men
det är inte möjligt på grund av mänskliga fel och konsekvenser av de verktyg vi
använder. För att undvika, exempelvis, 100\% av minnessårbarheter krävs
användning av minnessäkra programspråk (jfr eng. \emph{memory-safe language}).
Minnessäkra programspråk tilltar en kombination av körtids- (jfr eng.
\emph{runtime}) och kompileringstidskontroller (jfr eng. \emph{compile
    time checks}) för att undvika minnessårbarheter. Däremot finns det än idag
många skäl för att fortsätta använda minnesosäkra programspråk som C, såsom
prestandaskäl, hårdvarubegränsingar, men främst äldre kod som är mödosam att
skriva om~\cite{computer_security_cs161}. Dessutom är de nyare programspråken,
exempelvis Rust eller Swift, som kan konkurrera med C relativt nya och det
krävs tid för övergången mellan språken.

Två exempel på minnessårbarheter är buffertöverflöden (jfr eng. \emph{buffer
    overflow}) och formatsträngsbuggar (jfr eng. \emph{format string bug}). Den
vanligaste av de två är buffertöverflöden vilka uppstår av otillräckliga
gränskontroller (jfr eng. \emph{bounds checks}), och utlöser möjlighet till åtkomst bortom
gränserna för den minnesregion som avsetts. Angripare kan utnyttja detta för att korrumpera programmets
normala beteende genom att skriva bortom gränserna. Formatsträngsbuggar uppstår
när någon typ av indata tolkas och används som input till vanliga
textkonverteringsfunktioner som \texttt{printf}, som i sin tur använder
konvertingsfunktioner för konvertering av olika data till text. Om inte en
noggrann och tillräcklig utvärdering av indatan görs innan den används i en
funktion som kan tolka formatsträngar, kan funktionen använda stacken och den
data som råkar ligga där som argument till konverteringsfunktioner. Med noggrann
utformning av indata kan en angripare utnyttja formatsträngsbuggar för att
exekvera godtyckliga kommandon~\cite{computer_security_cs161}.




